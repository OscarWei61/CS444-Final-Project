{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"H4tz4T6Ogl22"},"outputs":[],"source":["# Import libraries\n","import cv2\n","import numpy as np\n","import os\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# you will be prompted with a window asking to grant permissions\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"id":"mzT5QjHwwPVS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746057108864,"user_tz":300,"elapsed":15597,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}},"outputId":"3ed05634-70ce-4f37-af8c-2d1cd6bb473b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# fill in the path in your Google Drive in the string below. Note: do not escape slashes or spaces\n","import os\n","datadir = \"/content/drive/MyDrive/ECE494_Project/\"\n","if not os.path.exists(datadir):\n","  !ln -s \"/content/drive/MyDrive/ECE494_Project/\" $datadir # TODO: Fill your Assignment 4 path\n","os.chdir(datadir)\n","!pwd"],"metadata":{"id":"nOyuD8wXwREN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746057135623,"user_tz":300,"elapsed":840,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}},"outputId":"6989fdbb-60bb-4182-8af0-fef26c0e2b51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ECE494_Project\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9A6UQ4Rgl23","outputId":"f71c62f5-3819-47dc-c0b0-aa2e112e7bf6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746057159674,"user_tz":300,"elapsed":69,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","Deep custom 3D CNN model initialized and set to eval mode.\n"]}],"source":["# Define the deep custom 3D CNN model\n","class DeepCrashNN(nn.Module):\n","    def __init__(self):\n","        super(DeepCrashNN, self).__init__()\n","        # Block 1: 3D Conv + BatchNorm + ReLU, spatial pooling only (temporal resolution remains)\n","        self.block1 = nn.Sequential(\n","            nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(16),\n","            nn.ReLU(),\n","            nn.Conv3d(in_channels=16, out_channels=16, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(16),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=(1, 2, 2))  # Only spatial pooling: reduces H & W by 2\n","        )\n","        # Block 2: Increase channels to 32\n","        self.block2 = nn.Sequential(\n","            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(32),\n","            nn.ReLU(),\n","            nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(32),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=(1, 2, 2))\n","        )\n","        # Block 3: Increase channels to 64 with global pooling at the end\n","        self.block3 = nn.Sequential(\n","            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(64),\n","            nn.ReLU(),\n","            nn.Conv3d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n","            nn.BatchNorm3d(64),\n","            nn.ReLU(),\n","            nn.AdaptiveAvgPool3d(1)  # Global average pooling over (T, H, W)\n","        )\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.fc = nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = self.block1(x)  # (B, 16, T, H/2, W/2)\n","        x = self.block2(x)  # (B, 32, T, H/4, W/4)\n","        x = self.block3(x)  # (B, 64, 1, 1, 1)\n","        x = x.view(x.size(0), -1)  # Flatten to (B, 64)\n","        x = self.dropout(x)\n","        x = self.fc(x)             # (B, 1)\n","        return torch.sigmoid(x)    # Probability in [0,1]\n","\n","# Instantiate the model and set it to evaluation mode\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","model = DeepCrashNN().to(device)\n","model.eval()\n","print(\"Deep custom 3D CNN model initialized and set to eval mode.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOTlPB0Jgl24","outputId":"a41453b0-faeb-42b0-8605-97a83fca589b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746057163676,"user_tz":300,"elapsed":995,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data loaded. Number of training videos: 1500\n","Test data loaded. Number of test videos: 1344\n"]}],"source":["# Load training and test CSV files\n","train_df = pd.read_csv('train.csv')\n","test_df = pd.read_csv('test.csv')\n","print(\"Training data loaded. Number of training videos:\", len(train_df))\n","print(\"Test data loaded. Number of test videos:\", len(test_df))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ayIM15JIgl24"},"outputs":[],"source":["# Define function to extract randomly sampled frames from a video\n","def extract_random_frames(video_path, num_frames=40, resize=(224, 224)):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(f\"Error opening video file: {video_path}\")\n","        return None\n","\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    if total_frames <= 0:\n","        cap.release()\n","        return None\n","\n","    # Randomly sample 'num_frames' unique indices and sort them to preserve temporal order\n","    frame_indices = sorted(np.random.choice(total_frames, num_frames, replace=False))\n","\n","    frames = []\n","    current_frame = 0\n","    next_idx = 0\n","    ret = True\n","    while ret and next_idx < len(frame_indices):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","        if current_frame == frame_indices[next_idx]:\n","            frame = cv2.resize(frame, resize)\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            frame = frame.astype(np.float32) / 255.0  # Normalize to [0,1]\n","            frames.append(frame)\n","            next_idx += 1\n","        current_frame += 1\n","    cap.release()\n","\n","    if len(frames) < num_frames:\n","        while len(frames) < num_frames:\n","            frames.append(frames[-1])\n","\n","    # Convert frames to tensor with shape (B, C, T, H, W)\n","    frames = np.stack(frames, axis=0)           # (T, H, W, C)\n","    frames = np.transpose(frames, (3, 0, 1, 2))   # (C, T, H, W)\n","    frames_tensor = torch.from_numpy(frames).unsqueeze(0)  # Add batch dimension\n","    return frames_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZTPQYdFCgl24"},"outputs":[],"source":["# Define prediction function\n","def predict_video(video_path):\n","    frames_tensor = extract_random_frames(video_path, num_frames=16, resize=(224,224))\n","    if frames_tensor is None:\n","        return 0.0  # Default probability if video cannot be processed\n","    frames_tensor = frames_tensor.to(device)\n","    with torch.no_grad():\n","        output = model(frames_tensor)  # Output shape: (B, 1)\n","        prob = output.item()\n","    return prob"]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class VideoDataset(Dataset):\n","    def __init__(self, df, video_dir, num_frames=16, resize=(224, 224)):\n","        self.df = df\n","        self.video_dir = video_dir\n","        self.num_frames = num_frames\n","        self.resize = resize\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        video_id = int(float(row['id']))\n","        label = torch.tensor([row['target']], dtype=torch.float32)  # label 必須是 float\n","        video_filename = f\"{video_id:05d}.mp4\"\n","        video_path = os.path.join(self.video_dir, video_filename)\n","\n","        frames = extract_random_frames(video_path, self.num_frames, self.resize)\n","        if frames is None:\n","            frames = torch.zeros((1, 3, self.num_frames, *self.resize))  # fallback\n","\n","        return frames.squeeze(0), label"],"metadata":{"id":"oaugOrFWoj_U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","train_split, val_split = train_test_split(train_df, test_size=0.2, random_state=42)\n","\n","train_dataset = VideoDataset(train_split, video_dir='./train')\n","val_dataset = VideoDataset(val_split, video_dir='./train')\n","\n","train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n","val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)"],"metadata":{"id":"AV29FpcLomZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 損失函數 & 優化器\n","#criterion = nn.BCELoss()\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","criterion = nn.BCEWithLogitsLoss()"],"metadata":{"id":"Imx9hwTjorys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 方式一：Adam\n","#optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# 方式二：SGD\n","#optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n","\n","# 方式三：RMSprop\n","#optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)"],"metadata":{"id":"D-utPXCzotdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","import matplotlib.pyplot as plt"],"metadata":{"id":"clRb0gyPot9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_val_loss = float('inf')\n","num_epochs = 30\n","\n","train_losses = []\n","val_losses = []\n","\n","for epoch in tqdm(range(num_epochs)):\n","    model.train()\n","    train_loss = 0\n","\n","    for videos, labels in train_loader:\n","        videos = videos.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(videos)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    avg_train_loss = train_loss / len(train_loader)\n","\n","    # ===== 驗證階段 =====\n","    model.eval()\n","    val_loss = 0\n","    with torch.no_grad():\n","        for videos, labels in val_loader:\n","            videos = videos.to(device)\n","            labels = labels.to(device)\n","            outputs = model(videos)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","\n","    # 儲存每個 epoch 的 loss\n","    train_losses.append(avg_train_loss)\n","    val_losses.append(avg_val_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n","\n","    # ===== 儲存最佳模型 =====\n","    if avg_val_loss < best_val_loss:\n","        best_val_loss = avg_val_loss\n","        torch.save(model.state_dict(), \"best_model.pth\")\n","        print(f\"新最佳模型已儲存（Val Loss: {best_val_loss:.4f}）\")\n","\n","# ===== 畫圖 =====\n","plt.plot(train_losses, label='Train Loss')\n","plt.plot(val_losses, label='Val Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training & Validation Loss Curve')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"id":"tZ-_D4jpovI8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"67864588-15dd-4949-bdf9-19b1bb4c0cd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  3%|▎         | 1/30 [51:57<25:06:56, 3117.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/30] - Train Loss: 0.7062 | Val Loss: 0.6904\n","新最佳模型已儲存（Val Loss: 0.6904）\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 2/30 [1:21:35<18:07:10, 2329.65s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/30] - Train Loss: 0.6949 | Val Loss: 0.6829\n","新最佳模型已儲存（Val Loss: 0.6829）\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 3/30 [1:51:08<15:33:56, 2075.42s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/30] - Train Loss: 0.6909 | Val Loss: 0.6863\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 4/30 [2:20:43<14:07:58, 1956.87s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/30] - Train Loss: 0.6877 | Val Loss: 0.6852\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 5/30 [2:50:21<13:08:26, 1892.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/30] - Train Loss: 0.6860 | Val Loss: 0.6805\n","新最佳模型已儲存（Val Loss: 0.6805）\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 6/30 [3:20:00<12:21:33, 1853.88s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [6/30] - Train Loss: 0.6817 | Val Loss: 0.6786\n","新最佳模型已儲存（Val Loss: 0.6786）\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 7/30 [3:49:38<11:41:07, 1829.02s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [7/30] - Train Loss: 0.6839 | Val Loss: 0.6793\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 8/30 [4:19:17<11:04:49, 1813.15s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [8/30] - Train Loss: 0.6789 | Val Loss: 0.6795\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 9/30 [4:48:50<10:30:07, 1800.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [9/30] - Train Loss: 0.6768 | Val Loss: 0.6755\n","新最佳模型已儲存（Val Loss: 0.6755）\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 10/30 [5:18:30<9:58:06, 1794.30s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [10/30] - Train Loss: 0.6750 | Val Loss: 0.6777\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 11/30 [5:48:07<9:26:30, 1788.99s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch [11/30] - Train Loss: 0.6727 | Val Loss: 0.6779\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dd6Uq8oBgl24","colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1746057223791,"user_tz":300,"elapsed":21140,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}},"outputId":"462e8f6e-9e37-4630-e0ba-84189f22e5d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 0 training videos...\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-73fcf5eba45f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mvideo_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{video_id:05d}.mp4\"\u001b[0m  \u001b[0;31m# e.g., 01924.mp4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-b22a2d47b36f>\u001b[0m in \u001b[0;36mpredict_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define prediction function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mframes_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_random_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mframes_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0.0\u001b[0m  \u001b[0;31m# Default probability if video cannot be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-5d2eb23e0654>\u001b[0m in \u001b[0;36mextract_random_frames\u001b[0;34m(video_path, num_frames, resize)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnext_idx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Generate predictions for training videos\n","train_predictions = []\n","\n","for idx, row in train_df.iterrows():\n","    # Convert video ID to integer and format with leading zeros (5 digits)\n","    video_id = int(float(row['id']))\n","    video_filename = f\"{video_id:05d}.mp4\"  # e.g., 01924.mp4\n","    video_path = os.path.join(\"train\", video_filename)\n","    prob = predict_video(video_path)\n","    train_predictions.append(prob)\n","    if idx % 50 == 0:\n","        print(f\"Processed {idx} training videos...\")\n","\n","train_df['predicted_score'] = train_predictions\n","print(\"Training predictions generated.\")"]},{"cell_type":"code","source":["model.load_state_dict(torch.load(\"best_model.pth\",map_location=torch.device('cpu')))\n","model.eval()"],"metadata":{"id":"rrPLOKH5o19R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746057302786,"user_tz":300,"elapsed":14,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}},"outputId":"3521ea5d-7ca6-4d27-e53c-b994063f8b3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DeepCrashNN(\n","  (block1): Sequential(\n","    (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (4): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (block2): Sequential(\n","    (0): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (4): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): MaxPool3d(kernel_size=(1, 2, 2), stride=(1, 2, 2), padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (block3): Sequential(\n","    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU()\n","    (3): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU()\n","    (6): AdaptiveAvgPool3d(output_size=1)\n","  )\n","  (dropout): Dropout(p=0.5, inplace=False)\n","  (fc): Linear(in_features=64, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65e41S2Ygl25","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746059433258,"user_tz":300,"elapsed":2123268,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}},"outputId":"9f3581f4-4d9a-44fc-f2d0-50ba59d940c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed 0 test videos...\n","Processed 50 test videos...\n","Processed 100 test videos...\n","Processed 150 test videos...\n","Processed 200 test videos...\n","Processed 250 test videos...\n","Processed 300 test videos...\n","Processed 350 test videos...\n","Processed 400 test videos...\n","Processed 450 test videos...\n","Processed 500 test videos...\n","Processed 550 test videos...\n","Processed 600 test videos...\n","Processed 650 test videos...\n","Processed 700 test videos...\n","Processed 750 test videos...\n","Processed 800 test videos...\n","Processed 850 test videos...\n","Processed 900 test videos...\n","Processed 950 test videos...\n","Processed 1000 test videos...\n","Processed 1050 test videos...\n","Processed 1100 test videos...\n","Processed 1150 test videos...\n","Processed 1200 test videos...\n","Processed 1250 test videos...\n","Processed 1300 test videos...\n","Test predictions generated.\n"]}],"source":["# Generate predictions for test videos\n","test_predictions = []\n","\n","for idx, row in test_df.iterrows():\n","    video_id = int(float(row['id']))\n","    video_filename = f\"{video_id:05d}.mp4\"\n","    video_path = os.path.join(\"test\", video_filename)\n","    prob = predict_video(video_path)\n","    test_predictions.append(prob)\n","    if idx % 50 == 0:\n","        print(f\"Processed {idx} test videos...\")\n","\n","test_df['score'] = test_predictions\n","print(\"Test predictions generated.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MYlN_PJ-gl25","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746059441108,"user_tz":300,"elapsed":500,"user":{"displayName":"kabo chang","userId":"02135712250441530671"}},"outputId":"5ef40374-19e6-4355-a576-e44697d90486"},"outputs":[{"output_type":"stream","name":"stdout","text":["Submission file 'submission.csv' created successfully.\n"]}],"source":["# Save submission file\n","submission = test_df[['id', 'score']]\n","submission.to_csv('submission.csv', index=False)\n","print(\"Submission file 'submission.csv' created successfully.\")"]},{"cell_type":"code","source":[],"metadata":{"id":"RNy3soyjQLFW"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}